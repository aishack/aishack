[unix_http_server]
file=/tmp/supervisor.sock                       ; path to your socket file

[supervisord]
logfile=/var/log/supervisor/supervisord.log     ; supervisord log file
logfile_maxbytes=50MB                           ; maximum size of logfile before rotation
logfile_backups=10                              ; number of backed up logfiles
loglevel=error                                  ; info, debug, warn, trace
pidfile=/var/run/supervisord.pid                ; pidfile location
nodaemon=false                                  ; run supervisord as a daemon
minfds=1024                                     ; number of startup file descriptors
minprocs=200                                    ; number of process descriptors
user=root                                       ; default user
childlogdir=/var/log/supervisor/                ; where child log files will live

[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[supervisorctl]
serverurl=unix:///tmp/supervisor.sock         ; use a unix:// URL  for a unix socket

; This is where you run individual Tornado instances.
; We run four; one per processor core.
; In development, we ran as many as four per core with no issues.
; If you're looking to minimize cpu load, run fewer processes.
; BTW, Tornado processes are single threaded.
; To take advantage of multiple cores, you'll need multiple processes.

[program:uwsgi]
command=uwsgi --ini aishack_uwsgi.ini
stopsignal=INT
directory=/work/aishack/
stderr_logfile = /tmp/uwsgi-stderr.log
stdout_logfile = /tmp/uwsgi-stdout.log
environment = 
priority=1000

[program:nginx]
command=/usr/sbin/nginx
stderr_logfile = /tmp/nginx-stderr.log
stdout_logfile = /tmp/nginx-stdout.log
priority=500

[program:redis]
command=/usr/bin/redis-server
stderr_logfile=/tmp/redis-stderr.log
stdout_logfile=/tmp/redis-stdout.log
priority=500

[program:es]
command=/usr/share/elasticsearch/bin/elasticsearch -Des.http.port=9201
numprocs=1
user = elasticsearch
environment = ES_HOME="/etc/elasticsearch"
priority=500
stderr_logfile=/tmp/elasticsearch-stderr.log
stdout_logfile=/tmp/elasticsearch-stdout.log

[program:varnish]
command=/usr/sbin/varnishd -f /work/aishack/varnish.vcl -a 0.0.0.0:8000 -s malloc,1G -F
directory=/work/aishack/
stderr_logfile = /tmp/varnish-stderr.log
stdout_logfile = /tmp/varnish-stdout.log
autorestart=true
